import numpy as np
import matplotlib.pyplot as plt

x_train = np.random.randn(1000)
y_train = np.random.randn(1000)



W = 0.0
b = 0.0

print(x_train)
print(y_train)

n_data = len(x_train)

epochs = 10000
learning_rate = 0.01


def gradient(W,b,x_train,y_train,n_data):
    gradient_w = np.sum((W * x_train - y_train + b) * 2 * x_train) / n_data
    gradient_b = np.sum((W * x_train - y_train + b) * 2) / n_data
    W -= learning_rate * gradient_w
    b -= learning_rate * gradient_b

    return W,b



for i in range(epochs):
    hypothesis = x_train * W + b
    cost = np.sum((hypothesis - y_train) ** 2) / n_data
    W,b = gradient(W,b,x_train,y_train,n_data)

    if i % 100 == 0:
        print('Epoch ({:10d}/{:10d}) cost: {:10f}, W: {:10f}, b:{:10f}'.format(i, epochs, cost, W, b))

print('W: {:10f}'.format(W))
print('b: {:10f}'.format(b))
print('result : ')
print(x_train,x_train * W + b)

plt.scatter(x_train,y_train)
x = np.linspace(-5,5,100)
y = W*x+b
plt.plot(x, y, '-r', label='y=Wx+b')
plt.title('Graph of y=Wx+b')
plt.xlabel('x', color='#1C2833')
plt.ylabel('y', color='#1C2833')
plt.legend(loc='upper left')
plt.grid()
plt.show()
